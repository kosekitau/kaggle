# 特徴量
## 作成物
- 目的変数との相関がかなり高いfruitsetとseedsを掛け算した特徴量が良いとcodeから分かったので、相関高いやつを総当たり的な感じで掛け算割り算した。重要度やPFIの結果を見ると特にfurit_seed、fruit_bar_massが良かった印象。
```python
# furitset, seed, fruitmassは目的変数との相関が0.8以上あった
df["fruit_seed"] = df["fruitset"] * df["seeds"] # 花から果実へ成熟した割合 * 果実1個あたりの平均種子数
df["fruit_bar_seed"] = df["fruitset"] / df["seeds"] 
df["fruit_mass"] = df["fruitset"] * df["fruitmass"] # 花から果実へ成熟した割合 * 果実1個あたりの平均質量
df["fruit_bar_mass"] = df["fruitset"] / df["fruitmass"] # 花から果実へ成熟した割合 / 果実1個あたりの平均質量(旧seed_fruitmass)
df["seed_mass"] = df["seeds"] * df["fruitmass"] 
df["seed_bar_mass"] = df["seeds"] / df["fruitmass"] # 果実1個あたりの平均種子数 / 果実1個あたりの平均質量
```
- Youtubeでブルーベリー農家の動画を漁ってたら、年によって畑にくるミツバチが違うと言っていたので、ミツバチの組み合わせクラスタのような特徴量を作ると良いかもと考えた。
  - なんとなくミツバチ系の特徴量4種類をUMAPに突っ込んだ。UMAPじゃなくて良かったかも。
  - そもそも今回ミツバチ系の特徴量がそもそも相関が低かったりしたせいかあまり精度は上がらなかった。
```python
bees = ["honeybee", 'bumbles', 'andrena', 'osmia']
X = StandardScaler().fit_transform(df[bees])
umap = UMAP(n_components=2, n_neighbors=50, random_state=228).fit(X)
df["bees_umap_x"] = umap.transform(X)[:, 0]
df["bees_umap_y"] = umap.transform(X)[:, 1]
```
## 最終的に使ったもの
- 

# モデル
- 以下を試した。
  - LightGBM
  - CatBoost

# アンサンブル
- 上記3つの(モデル+ハイパラ)の組み合わせに対して、random_stateだけ変更してモデルを学習させる作業を繰り返し、モデル数を合計30個までかさ増しさせた。
  - 参考：https://speakerdeck.com/rsakata/santander-product-recommendationfalseapurotitoxgboostfalsexiao-neta?slide=39
- 最終的な予測は単純に全モデルの予測の平均で出した。random_state変更かさ増しのおかげで、cvもpublicも0.00001くらいスコアが良くなった。

# cv
- cvするときにoriginalデータはtrain側にconcatするようにして、valid側には入れないようにした。
```python
KFold(n_splits=15, shuffle=True, random_state=random_state)
```

# 反省点

# 勉強になったもの
- flaml
  - AutoML系のモジュール。LBで上位に来てた。
  - https://www.kaggle.com/code/paddykb/ps-s3e14-flaml-bfi-be-bop-a-blueberry-do-dah

- hill crimbing
  - 複数モデルをアンサンブルしたい時に重みを決めるための手法。各モデルの出力の指数移動平均を取ることで決める形式になっており、指数移動平均をとる重みをグリッドサーチ的に探索する。
  - 4位の人の解法：https://www.kaggle.com/competitions/playground-series-s3e14/discussion/410639
  - 実装例：https://www.kaggle.com/code/samuelcortinhas/ps-s3e3-hill-climbing-like-a-gm

- RandomForest Regressorのoob_score=Trueにすることで、パラメータ探索の高速化
  - 今回評価指標がMAEだったので、"criterion":"absolute_error"を指定したいがこれだとめちゃくちゃ学習に時間がかかり、ハイパラ探索にも時間がかかる。
  - oobはブートストラップでサンプリングされなかったデータをさしており、学習後oobデータで予測精度を見ることで検証データでの精度計算的なことができ、kfoldするよりハイパラ探索が早くなりそう。
  - 13位の人の解法：https://www.kaggle.com/competitions/playground-series-s3e14/discussion/410652