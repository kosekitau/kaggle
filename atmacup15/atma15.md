
# 作戦
- train.csvに現れるユーザ(Seen)と、test.csvで初めて出てくるユーザ(UnSeen)に分けてそれぞれ別にモデルと特徴量と交差検証を考える。
- 過去に少し似たコンペに出た時、ユーザの特徴量を作るのが重要だったので、特徴量を作ることに時間を割く。

# 特徴量
Seen/UnSeen共通
- 最初から使える情報：members, watching, completed, on_hold, dropped, plan_to_watch, genres, type, producers, licensors, studios, source, rating
- 四則演算系：completed, on_hold, droppedをそれぞれmembersで割ったもの
- Word2vec + t-SNE系：anime_id
- Target Encoding：アニメの平均スコア

Seenだけ
- Target Encoding：
  - シリーズごとのユーザの平均スコア
    - レーベンシュタイン距離などでシリーズを定義しようとしたがうまくいかなかったので、各アニメタイトルの先頭5文字でシリーズラベルを与えた(例：ポケットモンスターXY→「ポケットモ」ラベル)。
      - 一部「劇場版」などが頭についてるので軽く前処理をして先頭5文字を抽出。
      - 文字数はなるべく短くしたいが4文字だと「魔法少女hogehoge」とかが全部同じにラベルになってしまうので5文字。アニメタイトルをソートして眺めてえいやで決めた。
    - 例：AさんがポケモンXYを見た時のスコアを予測したかったら、XY以外のポケモンシリーズの平均スコアを使う。
  - 年代ごとのユーザの平均スコア
    - アニメの流行り、思い出補正が大体5年周期で変わると考え、各アニメの放映日を5年ごとでグルーピングした。(ポケモンXYは2013年放映開始→2010年代ラベル)
    - 例：AさんがポケモンXY(2010年代ラベル)を見た時のスコアを予測したかったら、XY以外の2010年代ラベルの平均スコアを使う。
  - typeごとのユーザの平均スコア
    - 例：AさんがポケモンXY(TVタイプ)を見た時のスコアを予測したかったら、XY以外のTVタイプの平均スコアを使う
  - ratingごとのユーザの平均スコア
    - 例：AさんがポケモンXY(PG - Children)を見た時のスコアを予測したかったら、XY以外のPG - Childrenのアニメの平均スコアを使う
  - sourceごとのユーザの平均スコア
    - 例：AさんがポケモンXY(Game)を見た時のスコアを予測したかったら、XY以外のGameのアニメの平均スコアを使う
  - ユーザの平均スコア
  - Target Encoding系の特徴量はなるべくリークをしないように、交差検証内で逐次作る、LeaveOneOutEncoderを使うなど工夫をした。

# 交差検証
Seen
 - MultilabelStratifiedKFold(n_splits=5)
   - 学習データと検証データでscoreとuser_idの分布を同じにして、LBのSeen(既知)ユーザを予測する状況を再現したかったから。

UnSeen
 - StratifiedGroupKFold(n_splits=5)
   - 学習データと検証データでscoreの分布を同じにしたいかつ、学習データに出てくるユーザを検証データに出さないことによって、LBのUnSeen(未知)ユーザを予測する状況を再現したかったから。


# モデル
Seen
- (LightGBM + XGBoost) / 2  

UnSeen
- LightGBM

ハイパラ探索はOptunaに任せた。  
最後にSeenとUnSeenの予測をうまくmergeして完成。


# 感想
- 交差検証内でリークしてないか考えたり、特徴量の実装で時間をほぼ使ってしまった。
- レコメンド系のタスクで使われる手法を全く知らなかった。
- やりたいことがいっぱい出てきて、discussionちゃんと見てなかった(見よう)
- 知っている人が何人か出てるコンペに出るのは楽しい。